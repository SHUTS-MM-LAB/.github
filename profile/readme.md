# SotaHUnTerS Multi-Modal Lab

> _Chivalrous hunters, chasing SOTAs._

## üë®‚Äçüéì About us
We are SHUTS (**S**ota**HU**n**T**er**S**) MM Lab, a collaborative research group in the field of multi-modal learning, initiated by student researchers from Shanghai University (**SHU**) and the University of Technology Sydney (**UTS**). Our research interests include:

- CLIP-based prompt tuning
- Instance Segmentation
- LLM intelligent agents

## üî• Recent News
- (20 Mar. 2025) Jiacheng Sun's paper (**PolarNeXt: Rethink Instance Segmentation with Polar Representation**) is accepted by CVPR 2025!
- (18 Mar. 2025) Haoyang Li's paper ([**DPC: Dual-Prompt Collaboration for Tuning Vision-Language Models**](https://arxiv.org/abs/2503.13443)) is accepted by CVPR 2025!

## üóíÔ∏è Research List

| name                                                         | description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [DPC](https://arxiv.org/abs/2503.13443) <a href='https://github.com/JREion/DPC'><img src='https://img.shields.io/github/stars/JREion/DPC?style=social' /></a> | [CVPR 2025] Official PyTorch Code for "DPC: Dual-Prompt Collaboration for Tuning Vision-Language Models" |
| [PolarNeXt](https://github.com/Sun15194/PolarNeXt) <a href='https://github.com/Sun15194/PolarNeXt'><img src='https://img.shields.io/github/stars/Sun15194/PolarNeXt?style=social' /></a> | [CVPR 2025] PolarNeXt: Rethink Instance Segmentation with Polar Representation |

